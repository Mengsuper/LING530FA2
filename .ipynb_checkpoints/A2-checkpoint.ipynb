{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from random import random\n",
    "from nltk import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_emotion = []\n",
    "train_tweets = []\n",
    "with open('dataset/train.csv') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"', skipinitialspace=True)\n",
    "    line_count = 0\n",
    "    for row in spamreader:\n",
    "        line_count += 1\n",
    "        if line_count == 1: continue # skip header\n",
    "        if not row: continue\n",
    "        emotion = row[0]\n",
    "        tweet = row[1]\n",
    "        tweet = tweet.replace('@USERNAME', '')\n",
    "        tweet = tweet.replace('[#TRIGGERWORD#]', '')\n",
    "        tweet = result = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "        train_tweets.append(tweet)\n",
    "        train_emotion.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = train_tweets\n",
    "\n",
    "# Lower-case the sentence, tokenize them and add <SOS> and <EOS> tokens\n",
    "sentences = [[\"<SOS>\"] + word_tokenize(sentence.lower()) + [\"<EOS>\"] for sentence in sentences]\n",
    "\n",
    "# Create the vocabulary. Note that we add an <UNK> token to represent words not in our vocabulary.\n",
    "word_counts = Counter([word for sentence in sentences for word in sentence])\n",
    "vocabulary = [\"<UNK>\"] + [e[0] for e in list(word_counts.items()) if e[1] > 2]\n",
    "vocabularySize = len(vocabulary)\n",
    "word2index = {word:index for index,word in enumerate(vocabulary)}\n",
    "one_hot_embeddings = np.eye(vocabularySize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'disgust', 'fear', 'joy', 'sad', 'surprise']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create emotion array\n",
    "emotions = sorted(list(set(train_emotion)))\n",
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the word2vec embeddings\n",
    "wordEncodingSize = 300\n",
    "filtered_sentences = [[word for word in sentence if word in word2index] for sentence in sentences]\n",
    "w2v = Word2Vec(filtered_sentences, min_count=0, size=wordEncodingSize)\n",
    "w2v_embeddings = np.concatenate((np.zeros((1, wordEncodingSize)), w2v.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_numberize(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence, in the form of a string, this function will preprocess it\n",
    "    into list of numbers (denoting the index into the vocabulary).\n",
    "    \"\"\"\n",
    "    tokenized = word_tokenize(sentence.lower())\n",
    "        \n",
    "    # Add the <SOS>/<EOS> tokens and numberize (all unknown words are represented as <UNK>).\n",
    "    tokenized = [\"<SOS>\"] + tokenized + [\"<EOS>\"]\n",
    "    numberized = [word2index.get(word, 0) for word in tokenized]\n",
    "    \n",
    "    return numberized\n",
    "\n",
    "def preprocess_one_hot(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence, in the form of a string, this function will preprocess it\n",
    "    into a numpy array of one-hot vectors.\n",
    "    \"\"\"\n",
    "    numberized = preprocess_numberize(sentence)\n",
    "    \n",
    "    # Represent each word as it's one-hot embedding\n",
    "    one_hot_embedded = one_hot_embeddings[numberized]\n",
    "    \n",
    "    return one_hot_embedded\n",
    "\n",
    "def preprocess_word2vec(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence, in the form of a string, this function will preprocess it\n",
    "    into a numpy array of word2vec embeddings.\n",
    "    \"\"\"\n",
    "    numberized = preprocess_numberize(sentence)\n",
    "    \n",
    "    # Represent each word as it's one-hot embedding\n",
    "    w2v_embedded = w2v_embeddings[numberized]\n",
    "    \n",
    "    return w2v_embedded\n",
    "\n",
    "def compute_bleu(reference_sentence, predicted_sentence):\n",
    "    \"\"\"\n",
    "    Given a reference sentence, and a predicted sentence, compute the BLEU similary between them.\n",
    "    \"\"\"\n",
    "    reference_tokenized = word_tokenize(reference_sentence.lower())\n",
    "    predicted_tokenized = word_tokenize(predicted_sentence.lower())\n",
    "    return sentence_bleu([reference_tokenized], predicted_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build a Emotion Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderLSTM(\n",
       "  (lstm): LSTM(300, 300)\n",
       "  (out): Linear(in_features=300, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = False\n",
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = F.relu(input)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1) \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "'''\n",
    "# decoder for one hot embedding\n",
    "decoder=DecoderLSTM(input_size=len(vocabulary), \n",
    "                    hidden_size=300, \n",
    "                    output_size=len(emotions))\n",
    "'''\n",
    "# decoder for word2vec embedding\n",
    "decoder=DecoderLSTM(input_size=wordEncodingSize, \n",
    "                    hidden_size=300, \n",
    "                    output_size=len(emotions))\n",
    "decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train the Emotion Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build some helper function\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 0s (- 209m 9s) (0 0%) 0.117485\n",
      "2m 10s (- 331m 30s) (1000 0%) 0.101095\n",
      "3m 51s (- 292m 14s) (2000 1%) 0.101818\n",
      "5m 18s (- 265m 43s) (3000 1%) 0.100999\n",
      "7m 5s (- 264m 22s) (4000 2%) 0.100529\n",
      "9m 4s (- 268m 57s) (5000 3%) 0.100627\n",
      "10m 52s (- 266m 50s) (6000 3%) 0.100287\n",
      "12m 40s (- 264m 45s) (7000 4%) 0.100329\n",
      "14m 10s (- 257m 24s) (8000 5%) 0.100434\n",
      "15m 53s (- 254m 45s) (9000 5%) 0.100931\n",
      "17m 32s (- 251m 25s) (10000 6%) 0.100947\n",
      "19m 7s (- 247m 25s) (11000 7%) 0.100847\n",
      "20m 50s (- 245m 19s) (12000 7%) 0.100751\n",
      "22m 23s (- 241m 34s) (13000 8%) 0.100467\n",
      "23m 50s (- 237m 13s) (14000 9%) 0.100260\n",
      "25m 20s (- 233m 39s) (15000 9%) 0.100184\n",
      "26m 42s (- 229m 10s) (16000 10%) 0.099966\n",
      "28m 1s (- 224m 42s) (17000 11%) 0.099831\n",
      "29m 28s (- 221m 31s) (18000 11%) 0.099709\n",
      "30m 57s (- 218m 49s) (19000 12%) 0.099400\n",
      "32m 18s (- 215m 17s) (20000 13%) 0.099109\n",
      "33m 46s (- 212m 42s) (21000 13%) 0.098867\n",
      "35m 11s (- 209m 59s) (22000 14%) 0.098651\n",
      "36m 37s (- 207m 24s) (23000 15%) 0.098347\n",
      "38m 1s (- 204m 48s) (24000 15%) 0.098125\n",
      "39m 26s (- 202m 22s) (25000 16%) 0.097916\n",
      "40m 58s (- 200m 33s) (26000 16%) 0.097679\n",
      "42m 42s (- 199m 42s) (27000 17%) 0.097373\n",
      "44m 16s (- 198m 5s) (28000 18%) 0.097200\n",
      "45m 49s (- 196m 22s) (29000 18%) 0.097041\n",
      "47m 25s (- 194m 54s) (30000 19%) 0.096864\n",
      "49m 3s (- 193m 31s) (31000 20%) 0.096664\n",
      "50m 46s (- 192m 27s) (32000 20%) 0.096360\n",
      "52m 24s (- 191m 1s) (33000 21%) 0.096208\n",
      "54m 8s (- 189m 57s) (34000 22%) 0.095956\n",
      "56m 8s (- 189m 44s) (35000 22%) 0.095776\n",
      "58m 13s (- 189m 42s) (36000 23%) 0.095621\n",
      "60m 34s (- 190m 23s) (37000 24%) 0.095491\n",
      "62m 44s (- 190m 20s) (38000 24%) 0.095318\n",
      "64m 52s (- 190m 7s) (39000 25%) 0.095171\n",
      "67m 1s (- 189m 50s) (40000 26%) 0.094958\n",
      "69m 23s (- 190m 2s) (41000 26%) 0.094817\n",
      "71m 52s (- 190m 26s) (42000 27%) 0.094620\n",
      "74m 21s (- 190m 41s) (43000 28%) 0.094441\n",
      "76m 45s (- 190m 39s) (44000 28%) 0.094256\n",
      "79m 37s (- 191m 35s) (45000 29%) 0.094145\n",
      "81m 43s (- 190m 35s) (46000 30%) 0.094052\n",
      "83m 54s (- 189m 44s) (47000 30%) 0.093878\n",
      "86m 9s (- 188m 58s) (48000 31%) 0.093718\n",
      "89m 33s (- 190m 35s) (49000 31%) 0.093588\n",
      "92m 24s (- 190m 52s) (50000 32%) 0.093435\n",
      "95m 2s (- 190m 36s) (51000 33%) 0.093334\n",
      "97m 49s (- 190m 31s) (52000 33%) 0.093184\n",
      "100m 4s (- 189m 21s) (53000 34%) 0.093074\n",
      "102m 20s (- 188m 10s) (54000 35%) 0.092959\n",
      "104m 33s (- 186m 51s) (55000 35%) 0.092832\n",
      "107m 9s (- 186m 9s) (56000 36%) 0.092677\n",
      "109m 55s (- 185m 40s) (57000 37%) 0.092498\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-87fd82a3bb09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mtarget_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumberized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_emotion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mavg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-87fd82a3bb09>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(target_variable, emotion, decoder, decoder_optimizer, criterion, embeddings, teacher_force)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(target_variable, \n",
    "          emotion,\n",
    "          decoder, \n",
    "          decoder_optimizer, \n",
    "          criterion, \n",
    "          embeddings=w2v_embeddings,\n",
    "          teacher_force=True): \n",
    "    \"\"\"\n",
    "    Given a single training sample, go through a single step of training.\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    decoder_input = Variable(torch.FloatTensor([[embeddings[target_variable[0].data[0]]]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    decoder_hidden = (decoder.initHidden(), decoder.initHidden())\n",
    "\n",
    "    for di in range(0,target_variable.size(0)):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "\n",
    "        if teacher_force:\n",
    "            ni = target_variable[di].data[0]\n",
    "        else:          \n",
    "            ni = topi[0][0]\n",
    "        \n",
    "        decoder_input = Variable(torch.FloatTensor([[embeddings[ni]]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        if di == target_variable.size(0) - 2: \n",
    "            loss += criterion(decoder_output, emotion)\n",
    "        if vocabulary[ni] == \"<EOS>\":\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), 10.0)\n",
    "\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_variable.size(0)\n",
    "\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001) \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "\n",
    "num_epochs = 1\n",
    "numberized_emotion = [emotions.index(emotion) for emotion in train_emotion]\n",
    "target_emotion = Variable(torch.LongTensor(numberized_emotion))\n",
    "start = time.time()\n",
    "total_loss = 0\n",
    "avg_loss = []\n",
    "for _ in range(num_epochs):\n",
    "    for i,sentence in enumerate(train_tweets):\n",
    "        \n",
    "        numberized = preprocess_numberize(sentence)\n",
    "        if len(numberized) == 2:\n",
    "            continue\n",
    "        target_variable = Variable(torch.LongTensor(numberized[1:]))\n",
    "\n",
    "        loss = train(target_variable, target_emotion[i], decoder, decoder_optimizer, criterion)\n",
    "        total_loss += loss\n",
    "        avg_loss.append(total_loss/(i+1))\n",
    "        if i % 1000 == 0:\n",
    "            print('%s (%d %d%%) %.6f' % \n",
    "                  (timeSince(start, (i+1)/len(train_tweets)), i, (i+1)/len(train_tweets)*100, total_loss/(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(train_tweets)\n",
    "showPlot(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# after training, save model \n",
    "torch.save(decoder.state_dict(), 'decoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load previously training model:\n",
    "torch.load(decoder.load_state_dict(), ('decoder.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluate the Emotion decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_tweets = []\n",
    "with open('dataset/dev.csv') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"', skipinitialspace=True)\n",
    "    line_count = 0\n",
    "    for row in spamreader:\n",
    "        line_count += 1\n",
    "        if line_count == 1: continue # skip header\n",
    "        if not row: continue\n",
    "        tweet = row[1]\n",
    "        tweet = tweet.replace('@USERNAME', '')\n",
    "        tweet = tweet.replace('[#TRIGGERWORD#]', '')\n",
    "        tweet = result = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "        dev_tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_emotions = []\n",
    "with open('dataset/trial-v3.csv') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"', skipinitialspace=True)\n",
    "    line_count = 0\n",
    "    for row in spamreader:\n",
    "        line_count += 1\n",
    "        if line_count == 1: continue # skip header\n",
    "        if not row: continue\n",
    "        dev_emotions.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate(decoder, \n",
    "             target_variable, \n",
    "             embeddings=w2v_embeddings, \n",
    "             teacher_force=True):\n",
    "    \n",
    "    decoder_input = Variable(torch.FloatTensor([[embeddings[target_variable[0].data[0]]]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    decoder_hidden = (decoder.initHidden(),decoder.initHidden())\n",
    "    \n",
    "    softmax = nn.Softmax()\n",
    "    for di in range(0,target_variable.size(0)):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        \n",
    "        if teacher_force:\n",
    "            ni = target_variable[di].data[0]\n",
    "        else:          \n",
    "            ni = topi[0][0]\n",
    "\n",
    "        decoder_input = Variable(torch.FloatTensor([[embeddings[ni]]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        if di == target_variable.size(0) - 2: # last output \n",
    "            if dev_emotions[i] == emotions[topi[0][0]]:\n",
    "                return True\n",
    "            #print (dev_emotions[i], emotions[topi[0][0]])\n",
    "            \n",
    "        if vocabulary[ni] == \"<EOS>\":\n",
    "            break\n",
    "    return False\n",
    "\n",
    "# evaluate the model\n",
    "print (\"ground truth, model prediction\")\n",
    "correct_prediction_counts = 0\n",
    "for i,tweet in enumerate(dev_tweets): \n",
    "    numberized = preprocess_numberize(tweet)\n",
    "    if len(numberized) == 2: continue\n",
    "    target_variable = Variable(torch.LongTensor(numberized[1:]))\n",
    "    \n",
    "    if evaluate(decoder, target_variable):\n",
    "        correct_prediction_counts += 1\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print (correct_prediction_counts, \" correct predictions in \", i+1)\n",
    "        print (\"acurray: \", correct_prediction_counts/(i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
