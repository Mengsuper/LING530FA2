{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from random import random\n",
    "from nltk import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_emotion = []\n",
    "train_tweets = []\n",
    "with open('dataset/train.csv') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"', skipinitialspace=True)\n",
    "    line_count = 0\n",
    "    for row in spamreader:\n",
    "        line_count += 1\n",
    "        if line_count == 1: continue # skip header\n",
    "        if not row: continue\n",
    "        emotion = row[0]\n",
    "        tweet = row[1]\n",
    "        tweet = tweet.replace('@USERNAME', '')\n",
    "        tweet = tweet.replace('[#TRIGGERWORD#]', '')\n",
    "        tweet = result = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "        train_tweets.append(tweet)\n",
    "        train_emotion.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = train_tweets\n",
    "\n",
    "# Lower-case the sentence, tokenize them and add <SOS> and <EOS> tokens\n",
    "sentences = [[\"<SOS>\"] + word_tokenize(sentence.lower()) + [\"<EOS>\"] for sentence in sentences]\n",
    "\n",
    "# Create the vocabulary. Note that we add an <UNK> token to represent words not in our vocabulary.\n",
    "word_counts = Counter([word for sentence in sentences for word in sentence])\n",
    "vocabulary = [\"<UNK>\"] + [e[0] for e in list(word_counts.items()) if e[1] > 2]\n",
    "vocabularySize = len(vocabulary)\n",
    "word2index = {word:index for index,word in enumerate(vocabulary)}\n",
    "one_hot_embeddings = np.eye(vocabularySize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'disgust', 'fear', 'joy', 'sad', 'surprise']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create emotion array\n",
    "emotions = sorted(list(set(train_emotion)))\n",
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Danielz/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Build the word2vec embeddings\n",
    "wordEncodingSize = 300\n",
    "filtered_sentences = [[word for word in sentence if word in word2index] for sentence in sentences]\n",
    "w2v = Word2Vec(filtered_sentences, min_count=0, size=wordEncodingSize)\n",
    "w2v_embeddings = np.concatenate((np.zeros((1, wordEncodingSize)), w2v.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_numberize(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence, in the form of a string, this function will preprocess it\n",
    "    into list of numbers (denoting the index into the vocabulary).\n",
    "    \"\"\"\n",
    "    tokenized = word_tokenize(sentence.lower())\n",
    "        \n",
    "    # Add the <SOS>/<EOS> tokens and numberize (all unknown words are represented as <UNK>).\n",
    "    tokenized = [\"<SOS>\"] + tokenized + [\"<EOS>\"]\n",
    "    numberized = [word2index.get(word, 0) for word in tokenized]\n",
    "    \n",
    "    return numberized\n",
    "\n",
    "def preprocess_one_hot(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence, in the form of a string, this function will preprocess it\n",
    "    into a numpy array of one-hot vectors.\n",
    "    \"\"\"\n",
    "    numberized = preprocess_numberize(sentence)\n",
    "    \n",
    "    # Represent each word as it's one-hot embedding\n",
    "    one_hot_embedded = one_hot_embeddings[numberized]\n",
    "    \n",
    "    return one_hot_embedded\n",
    "\n",
    "def preprocess_word2vec(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence, in the form of a string, this function will preprocess it\n",
    "    into a numpy array of word2vec embeddings.\n",
    "    \"\"\"\n",
    "    numberized = preprocess_numberize(sentence)\n",
    "    \n",
    "    # Represent each word as it's one-hot embedding\n",
    "    w2v_embedded = w2v_embeddings[numberized]\n",
    "    \n",
    "    return w2v_embedded\n",
    "\n",
    "def compute_bleu(reference_sentence, predicted_sentence):\n",
    "    \"\"\"\n",
    "    Given a reference sentence, and a predicted sentence, compute the BLEU similary between them.\n",
    "    \"\"\"\n",
    "    reference_tokenized = word_tokenize(reference_sentence.lower())\n",
    "    predicted_tokenized = word_tokenize(predicted_sentence.lower())\n",
    "    return sentence_bleu([reference_tokenized], predicted_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build a Emotion Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderLSTM(\n",
       "  (lstm): LSTM(300, 300, bidirectional=True)\n",
       "  (out): Linear(in_features=600, out_features=6)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = False\n",
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, bidirectional = True)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = F.relu(input)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1) \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(2, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "'''\n",
    "# decoder for one hot embedding\n",
    "decoder=DecoderLSTM(input_size=len(vocabulary), \n",
    "                    hidden_size=300, \n",
    "                    output_size=len(emotions))\n",
    "'''\n",
    "# decoder for word2vec embedding\n",
    "decoder=DecoderLSTM(input_size=wordEncodingSize, \n",
    "                    hidden_size=300, \n",
    "                    output_size=len(emotions))\n",
    "decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train the Emotion Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build some helper function\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 0s (- 354m 30s) (0 0%) 0.119164\n"
     ]
    }
   ],
   "source": [
    "def train(target_variable, \n",
    "          emotion,\n",
    "          decoder, \n",
    "          decoder_optimizer, \n",
    "          criterion, \n",
    "          embeddings=w2v_embeddings,\n",
    "          teacher_force=True): \n",
    "    \"\"\"\n",
    "    Given a single training sample, go through a single step of training.\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    decoder_input = Variable(torch.FloatTensor([[embeddings[target_variable[0].data[0]]]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    decoder_hidden = (decoder.initHidden(), decoder.initHidden())\n",
    "\n",
    "    for di in range(0,target_variable.size(0)):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "\n",
    "        if teacher_force:\n",
    "            ni = target_variable[di].data[0]\n",
    "        else:          \n",
    "            ni = topi[0][0]\n",
    "        \n",
    "        decoder_input = Variable(torch.FloatTensor([[embeddings[ni]]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        if di == target_variable.size(0) - 2: \n",
    "            loss += criterion(decoder_output, emotion)\n",
    "        if vocabulary[ni] == \"<EOS>\":\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), 10.0)\n",
    "\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_variable.size(0)\n",
    "\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001) \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "\n",
    "num_epochs = 2\n",
    "numberized_emotion = [emotions.index(emotion) for emotion in train_emotion]\n",
    "target_emotion = Variable(torch.LongTensor(numberized_emotion))\n",
    "start = time.time()\n",
    "total_loss = 0\n",
    "avg_loss = []\n",
    "for _ in range(num_epochs):\n",
    "    for i,sentence in enumerate(train_tweets):\n",
    "        \n",
    "        numberized = preprocess_numberize(sentence)\n",
    "        if len(numberized) == 2:\n",
    "            continue\n",
    "        target_variable = Variable(torch.LongTensor(numberized[1:]))\n",
    "\n",
    "        loss = train(target_variable, target_emotion[i], decoder, decoder_optimizer, criterion)\n",
    "        total_loss += loss\n",
    "        avg_loss.append(total_loss/(i+1))\n",
    "        if i % 1000 == 0:\n",
    "            print('%s (%d %d%%) %.6f' % \n",
    "                  (timeSince(start, (i+1)/len(train_tweets)), i, (i+1)/len(train_tweets)*100, total_loss/(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(train_tweets)\n",
    "showPlot(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# after training, save model \n",
    "torch.save(decoder.state_dict(), 'decoder2ep001lr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load previously training model:\n",
    "decoder.load_state_dict(torch.load('decoder1ep001lr.pt'))\n",
    "# torch.load(decoder.load_state_dict(), ('decoder_lr0.001.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluate the Emotion decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9592\n",
      "9591\n"
     ]
    }
   ],
   "source": [
    "dev_tweets = []\n",
    "\n",
    "print(sum(1 for line in open('dataset/dev.csv')))\n",
    "\n",
    "with open('dataset/dev.csv') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"', skipinitialspace=True, quoting=csv.QUOTE_NONE)\n",
    "    line_count = 0\n",
    "    for row in spamreader:\n",
    "        line_count += 1\n",
    "        if line_count == 1: continue # skip header\n",
    "        if not row: \n",
    "            continue\n",
    "        tweet = row[1]\n",
    "        tweet = tweet.replace('@USERNAME', '')\n",
    "        tweet = tweet.replace('[#TRIGGERWORD#]', '')\n",
    "        tweet = result = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "        dev_tweets.append(tweet)\n",
    "print(len(dev_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_emotions = []\n",
    "with open('dataset/trial-v3.csv') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"', skipinitialspace=True)\n",
    "    line_count = 0\n",
    "    for row in spamreader:\n",
    "        line_count += 1\n",
    "        if line_count == 1: continue # skip header\n",
    "        if not row: continue\n",
    "        dev_emotions.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth, model prediction\n",
      "1  correct predictions in  1\n",
      "acurray:  1.0\n",
      "46  correct predictions in  101\n",
      "acurray:  0.45544554455445546\n",
      "92  correct predictions in  201\n",
      "acurray:  0.4577114427860697\n",
      "140  correct predictions in  301\n",
      "acurray:  0.46511627906976744\n",
      "186  correct predictions in  401\n",
      "acurray:  0.46384039900249374\n",
      "241  correct predictions in  501\n",
      "acurray:  0.4810379241516966\n",
      "278  correct predictions in  601\n",
      "acurray:  0.46256239600665555\n",
      "323  correct predictions in  701\n",
      "acurray:  0.4607703281027104\n",
      "370  correct predictions in  801\n",
      "acurray:  0.46192259675405745\n",
      "408  correct predictions in  901\n",
      "acurray:  0.4528301886792453\n",
      "448  correct predictions in  1001\n",
      "acurray:  0.44755244755244755\n",
      "487  correct predictions in  1101\n",
      "acurray:  0.44232515894641233\n",
      "522  correct predictions in  1201\n",
      "acurray:  0.43463780183180684\n",
      "562  correct predictions in  1301\n",
      "acurray:  0.43197540353574176\n",
      "605  correct predictions in  1401\n",
      "acurray:  0.4318344039971449\n",
      "652  correct predictions in  1501\n",
      "acurray:  0.4343770819453698\n",
      "703  correct predictions in  1601\n",
      "acurray:  0.4391005621486571\n",
      "743  correct predictions in  1701\n",
      "acurray:  0.4368018812463257\n",
      "784  correct predictions in  1801\n",
      "acurray:  0.43531371460299834\n",
      "826  correct predictions in  1901\n",
      "acurray:  0.43450815360336664\n",
      "871  correct predictions in  2001\n",
      "acurray:  0.4352823588205897\n",
      "913  correct predictions in  2101\n",
      "acurray:  0.43455497382198954\n",
      "952  correct predictions in  2201\n",
      "acurray:  0.4325306678782372\n",
      "1000  correct predictions in  2301\n",
      "acurray:  0.43459365493263796\n",
      "1049  correct predictions in  2401\n",
      "acurray:  0.43690129112869636\n",
      "1098  correct predictions in  2501\n",
      "acurray:  0.43902439024390244\n",
      "1153  correct predictions in  2601\n",
      "acurray:  0.44329104190695884\n",
      "1200  correct predictions in  2701\n",
      "acurray:  0.44427989633469084\n",
      "1250  correct predictions in  2801\n",
      "acurray:  0.4462691895751517\n",
      "1287  correct predictions in  2901\n",
      "acurray:  0.4436401240951396\n",
      "1329  correct predictions in  3001\n",
      "acurray:  0.4428523825391536\n",
      "1377  correct predictions in  3101\n",
      "acurray:  0.4440503063527894\n",
      "1414  correct predictions in  3201\n",
      "acurray:  0.44173695720087475\n",
      "1459  correct predictions in  3301\n",
      "acurray:  0.4419872765828537\n",
      "1509  correct predictions in  3401\n",
      "acurray:  0.4436930314613349\n",
      "1559  correct predictions in  3501\n",
      "acurray:  0.445301342473579\n",
      "1602  correct predictions in  3601\n",
      "acurray:  0.4448764232157734\n",
      "1648  correct predictions in  3701\n",
      "acurray:  0.4452850580924075\n",
      "1697  correct predictions in  3801\n",
      "acurray:  0.44646145751118127\n",
      "1748  correct predictions in  3901\n",
      "acurray:  0.4480902332735196\n",
      "1791  correct predictions in  4001\n",
      "acurray:  0.4476380904773807\n",
      "1843  correct predictions in  4101\n",
      "acurray:  0.4494025847354304\n",
      "1886  correct predictions in  4201\n",
      "acurray:  0.4489407283980005\n",
      "1929  correct predictions in  4301\n",
      "acurray:  0.44850034875610323\n",
      "1973  correct predictions in  4401\n",
      "acurray:  0.4483072029084299\n",
      "2014  correct predictions in  4501\n",
      "acurray:  0.4474561208620307\n",
      "2056  correct predictions in  4601\n",
      "acurray:  0.4468593783960009\n",
      "2094  correct predictions in  4701\n",
      "acurray:  0.4454371410338226\n",
      "2143  correct predictions in  4801\n",
      "acurray:  0.44636534055405125\n",
      "2187  correct predictions in  4901\n",
      "acurray:  0.4462354621505815\n",
      "2232  correct predictions in  5001\n",
      "acurray:  0.44631073785242953\n",
      "2276  correct predictions in  5101\n",
      "acurray:  0.4461870221525191\n",
      "2320  correct predictions in  5201\n",
      "acurray:  0.4460680638338781\n",
      "2360  correct predictions in  5301\n",
      "acurray:  0.44519901905300885\n",
      "2399  correct predictions in  5401\n",
      "acurray:  0.4441770042584707\n",
      "2444  correct predictions in  5501\n",
      "acurray:  0.44428285766224324\n",
      "2495  correct predictions in  5601\n",
      "acurray:  0.4454561685413319\n",
      "2540  correct predictions in  5701\n",
      "acurray:  0.44553587089984215\n",
      "2580  correct predictions in  5801\n",
      "acurray:  0.4447509050163765\n",
      "2622  correct predictions in  5901\n",
      "acurray:  0.4443314692425013\n",
      "2669  correct predictions in  6001\n",
      "acurray:  0.4447592067988669\n",
      "2710  correct predictions in  6101\n",
      "acurray:  0.4441894771348959\n",
      "2753  correct predictions in  6201\n",
      "acurray:  0.4439606515078213\n",
      "2792  correct predictions in  6301\n",
      "acurray:  0.44310426916362483\n",
      "2835  correct predictions in  6401\n",
      "acurray:  0.4428995469457897\n",
      "2879  correct predictions in  6501\n",
      "acurray:  0.44285494539301645\n",
      "2934  correct predictions in  6601\n",
      "acurray:  0.4444781093773671\n",
      "2981  correct predictions in  6701\n",
      "acurray:  0.44485897627219817\n",
      "3029  correct predictions in  6801\n",
      "acurray:  0.4453756800470519\n",
      "3079  correct predictions in  6901\n",
      "acurray:  0.4461672221417186\n",
      "3110  correct predictions in  7001\n",
      "acurray:  0.44422225396371945\n",
      "3150  correct predictions in  7101\n",
      "acurray:  0.4435994930291508\n",
      "3199  correct predictions in  7201\n",
      "acurray:  0.4442438550201361\n",
      "3249  correct predictions in  7301\n",
      "acurray:  0.44500753321462816\n",
      "3297  correct predictions in  7401\n",
      "acurray:  0.4454803404945278\n",
      "3338  correct predictions in  7501\n",
      "acurray:  0.4450073323556859\n",
      "3384  correct predictions in  7601\n",
      "acurray:  0.44520457834495464\n",
      "3421  correct predictions in  7701\n",
      "acurray:  0.4442280223347617\n",
      "3465  correct predictions in  7801\n",
      "acurray:  0.4441738238687348\n",
      "3511  correct predictions in  7901\n",
      "acurray:  0.4443741298569801\n",
      "3560  correct predictions in  8001\n",
      "acurray:  0.44494438195225594\n",
      "3609  correct predictions in  8101\n",
      "acurray:  0.4455005554869769\n",
      "3665  correct predictions in  8201\n",
      "acurray:  0.4468967199122058\n",
      "3710  correct predictions in  8301\n",
      "acurray:  0.44693410432478015\n",
      "3755  correct predictions in  8401\n",
      "acurray:  0.44697059873824546\n",
      "3802  correct predictions in  8501\n",
      "acurray:  0.44724150099988236\n",
      "3841  correct predictions in  8601\n",
      "acurray:  0.44657597953726313\n",
      "3886  correct predictions in  8701\n",
      "acurray:  0.4466153315710838\n",
      "3937  correct predictions in  8801\n",
      "acurray:  0.44733553005340304\n",
      "3980  correct predictions in  8901\n",
      "acurray:  0.44714077069992136\n",
      "4023  correct predictions in  9001\n",
      "acurray:  0.44695033885123875\n",
      "4071  correct predictions in  9101\n",
      "acurray:  0.4473134820349412\n",
      "4108  correct predictions in  9201\n",
      "acurray:  0.4464732094337572\n",
      "4146  correct predictions in  9301\n",
      "acurray:  0.44575852058918397\n",
      "4195  correct predictions in  9401\n",
      "acurray:  0.4462291245612169\n",
      "4237  correct predictions in  9501\n",
      "acurray:  0.44595305757288706\n"
     ]
    }
   ],
   "source": [
    "actual_result = []\n",
    "def evaluate(decoder, \n",
    "             target_variable, \n",
    "             embeddings=w2v_embeddings, \n",
    "             teacher_force=True):\n",
    "    \n",
    "    decoder_input = Variable(torch.FloatTensor([[embeddings[target_variable[0].data[0]]]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    decoder_hidden = (decoder.initHidden(),decoder.initHidden())\n",
    "    \n",
    "    softmax = nn.Softmax()\n",
    "    for di in range(0,target_variable.size(0)):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        \n",
    "        if teacher_force:\n",
    "            ni = target_variable[di].data[0]\n",
    "        else:          \n",
    "            ni = topi[0][0]\n",
    "\n",
    "        decoder_input = Variable(torch.FloatTensor([[embeddings[ni]]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        if di == target_variable.size(0) - 2: # last output \n",
    "            actual_result.append(emotions[topi[0][0]])\n",
    "            if dev_emotions[i] == emotions[topi[0][0]]:\n",
    "                return True\n",
    "            #print (dev_emotions[i], emotions[topi[0][0]])\n",
    "            \n",
    "        if vocabulary[ni] == \"<EOS>\":\n",
    "            break\n",
    "    return False\n",
    "\n",
    "# evaluate the model\n",
    "print (\"ground truth, model prediction\")\n",
    "correct_prediction_counts = 0\n",
    "for i,tweet in enumerate(dev_tweets): \n",
    "    numberized = preprocess_numberize(tweet)\n",
    "    if len(numberized) == 2: continue\n",
    "    target_variable = Variable(torch.LongTensor(numberized[1:]))\n",
    "    \n",
    "    if evaluate(decoder, target_variable):\n",
    "        correct_prediction_counts += 1\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print (correct_prediction_counts, \" correct predictions in \", i+1)\n",
    "        print (\"acurray: \", correct_prediction_counts/(i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: surprise;joy;sad;disgust;fear;anger\n",
      "Label\tTP\tFP\tFN\tP\tR\tF\n",
      "surpris\t902\t1639\t698\t0.355\t0.564\t0.436\n",
      "joy\t939\t557\t797\t0.628\t0.541\t0.581\n",
      "sad\t341\t248\t1119\t0.579\t0.234\t0.333\n",
      "disgust\t824\t1206\t773\t0.406\t0.516\t0.454\n",
      "fear\t646\t525\t952\t0.552\t0.404\t0.467\n",
      "anger\t633\t1131\t967\t0.359\t0.396\t0.376\n",
      "MicAvg\t4285\t5306\t5306\t0.447\t0.447\t0.447\n",
      "MacAvg\t\t\t\t0.48\t0.442\t0.441\n",
      "Official result: 0.44114255759708526\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.395625</td>\n",
       "      <td>0.154375</td>\n",
       "      <td>0.076250</td>\n",
       "      <td>0.091875</td>\n",
       "      <td>0.031875</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.131497</td>\n",
       "      <td>0.515967</td>\n",
       "      <td>0.033813</td>\n",
       "      <td>0.039449</td>\n",
       "      <td>0.053225</td>\n",
       "      <td>0.226049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.169587</td>\n",
       "      <td>0.119524</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.050688</td>\n",
       "      <td>0.016270</td>\n",
       "      <td>0.239675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.114055</td>\n",
       "      <td>0.104839</td>\n",
       "      <td>0.065092</td>\n",
       "      <td>0.540899</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>0.171233</td>\n",
       "      <td>0.226027</td>\n",
       "      <td>0.086986</td>\n",
       "      <td>0.113014</td>\n",
       "      <td>0.233562</td>\n",
       "      <td>0.169178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.126250</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.068125</td>\n",
       "      <td>0.063125</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>0.563750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# Author: roman.klinger@ims.uni-stuttgart.de\n",
    "# Evaluation script for IEST at WASSA 2018\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def eprint(*args, **kwargs):\n",
    "    print(*args, file=sys.stderr, **kwargs)\n",
    "\n",
    "def welcome():\n",
    "    eprint(\"====================================\")\n",
    "    eprint(\"Evaluation script v0.2 for the Implicit Emotions Shared Task 2018.\")\n",
    "    eprint(\"Please call it via\")\n",
    "    eprint(\"./evaluate-iest.py <gold> <prediction>\")\n",
    "    eprint(\"where each csv file has labels in its first column.\")\n",
    "    eprint(\"The rows correspond to each other (1st row in <gold>\")\n",
    "    eprint(\"is the gold label for the 1st column in <prediction>).\")\n",
    "    eprint(\"\")\n",
    "    eprint(\"If you have questions, please contact klinger@wassa2018.com\")\n",
    "    eprint(\"====================================\\n\\n\")\n",
    "\n",
    "def checkParameters():\n",
    "    if ((len(sys.argv) < 3 or len(sys.argv) > 3)):\n",
    "        eprint(\"Please call the script with two files as parameters.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def readFileToList(filename):\n",
    "    eprint(\"Reading data from\",filename)\n",
    "    f=open(filename,\"r\")\n",
    "    lines=f.readlines()\n",
    "    result=[]\n",
    "    for x in lines:\n",
    "        result.append(x.split('\\t')[0].rstrip())\n",
    "    f.close()\n",
    "    eprint(\"Read\",len(result),\"labels.\")\n",
    "    return result\n",
    "\n",
    "def calculatePRF(gold,prediction):\n",
    "    # initialize counters\n",
    "    labels = set(gold+prediction)\n",
    "    print(\"Labels: \"+';'.join(labels))\n",
    "    tp = dict.fromkeys(labels, 0.0)\n",
    "    fp = dict.fromkeys(labels, 0.0)\n",
    "    fn = dict.fromkeys(labels, 0.0)\n",
    "    precision = dict.fromkeys(labels, 0.0)\n",
    "    recall = dict.fromkeys(labels, 0.0)\n",
    "    f = dict.fromkeys(labels, 0.0)\n",
    "    # check every element\n",
    "    for g,p in zip(gold,prediction):\n",
    "        #        print(g,p)\n",
    "        # TP \n",
    "        if (g == p):\n",
    "            tp[g] += 1\n",
    "        else:\n",
    "            fp[p] += 1\n",
    "            fn[g] += 1\n",
    "    # print stats\n",
    "    print(\"Label\\tTP\\tFP\\tFN\\tP\\tR\\tF\")\n",
    "    for label in labels:\n",
    "        recall[label] = 0.0 if (tp[label]+fn[label]) == 0.0 else (tp[label])/(tp[label]+fn[label])\n",
    "        precision[label] = 1.0 if (tp[label]+fp[label]) == 0.0 else (tp[label])/(tp[label]+fp[label])\n",
    "        f[label] = 0.0 if (precision[label]+recall[label])==0 else (2*precision[label]*recall[label])/(precision[label]+recall[label])\n",
    "        print(label[:7]+\n",
    "            \"\\t\"+str(int(tp[label]))+\n",
    "            \"\\t\"+str(int(fp[label]))+\n",
    "            \"\\t\"+str(int(fn[label]))+\n",
    "            \"\\t\"+str(round(precision[label],3))+\n",
    "            \"\\t\"+str(round(recall[label],3))+\n",
    "            \"\\t\"+str(round(f[label],3))\n",
    "            )\n",
    "        # micro average\n",
    "        microrecall = (sum(tp.values()))/(sum(tp.values())+sum(fn.values()))\n",
    "        microprecision = (sum(tp.values()))/(sum(tp.values())+sum(fp.values()))\n",
    "        microf = 0.0 if (microprecision+microrecall)==0 else (2*microprecision*microrecall)/(microprecision+microrecall)\n",
    "    # Micro average\n",
    "    print(\"MicAvg\"+\n",
    "        \"\\t\"+str(int(sum(tp.values())))+\n",
    "        \"\\t\"+str(int(sum(fp.values())))+\n",
    "        \"\\t\"+str(int(sum(fn.values())))+\n",
    "        \"\\t\"+str(round(microprecision,3))+\n",
    "        \"\\t\"+str(round(microrecall,3))+\n",
    "        \"\\t\"+str(round(microf,3))\n",
    "        )\n",
    "    # Macro average\n",
    "    macrorecall = sum(recall.values())/len(recall)\n",
    "    macroprecision = sum(precision.values())/len(precision)\n",
    "    macroF = sum(f.values())/len(f)\n",
    "    print(\"MacAvg\"+\n",
    "        \"\\t\"+str( )+\n",
    "        \"\\t\"+str( )+\n",
    "        \"\\t\"+str( )+\n",
    "        \"\\t\"+str(round(macroprecision,3))+\n",
    "        \"\\t\"+str(round(macrorecall,3))+\n",
    "        \"\\t\"+str(round(macroF,3))\n",
    "        )\n",
    "    print(\"Official result:\",macroF)\n",
    "        \n",
    "if (len(actual_result) != len(dev_emotions)):\n",
    "    eprint(\"Number of labels is not aligned!\")\n",
    "    sys.exit(1)\n",
    "calculatePRF(dev_emotions,actual_result)\n",
    "\n",
    "percent_matrix = [[0 for col in range(6)] for row in range(6)]\n",
    "for i in range(len(dev_emotions)):\n",
    "    percent_matrix[emotions.index(dev_emotions[i])][emotions.index(actual_result[i])] += 1\n",
    "\n",
    "dim_matrix = len(percent_matrix)\n",
    "col_sum = [0] * len(emotions)\n",
    "for i in range(dim_matrix):\n",
    "    for j in range(dim_matrix):\n",
    "        col_sum[i] = col_sum[i] + percent_matrix[i][j]\n",
    "        \n",
    "for i in range(len(percent_matrix)):\n",
    "    for j in range(len(percent_matrix)):\n",
    "        percent_matrix[i][j] = percent_matrix[i][j] / col_sum[i]\n",
    "        \n",
    "percent_matrix=pd.DataFrame(percent_matrix, columns = emotions, index = emotions)\n",
    "display(HTML(percent_matrix.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
